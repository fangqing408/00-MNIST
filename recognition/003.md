# 前向传播

## 1 >> `convolve_2D` 函数

包含两个参数，输入的特征图（第一次是原始图像），和卷积核，从这两个参数的 shape 属性里面能得到需要的信息，特征图的大小和通道数，卷积核的大小，输入输出通道数。

然后卷积之前先对这个特征图进行 pdding，确保卷积之后不影响特征图的大小。

```
def convolve_2D(input_matrix, kernel):
    input_height, input_width, input_channels = input_matrix.shape
    kernel_height, kernel_width, in_channels, out_channels = kernel.shape
    padding_size = kernel_height // 2
    ...
```

输出图像的大小就等于输入图像的大小，后面进行卷积即可。

```
    ...
    for c in range(out_channels):
        for i in range(output_height):
            for j in range(output_width):
                window = matrix_padding[i:i + kernel_height, j:j + kernel_width, :]
                output_matrix[i, j, c] = np.sum(window * kernel[:, :, :, c])
    return output_matrix
```

## 2 >> `max_pooling` 函数

将输入的特征图进行最大池化，特征图的大小缩小一半。

```
def max_pooling(input_matrix):
    input_height, input_width, input_channels = input_matrix.shape
    pooled_rows, pooled_cols = input_height // 2, input_width // 2
    output_matrix = np.zeros((pooled_rows, pooled_cols, input_channels))
    pool_indices = np.zeros((pooled_rows, pooled_cols, input_channels, 2), dtype=int)
```

下面是最大池化的具体实现，分别记录最大池化后的结果，和最大池化选择的下标，也就是矩阵 `pool_indices`，因为反向传播的时候需要。

```
    ...
    for c in range(input_channels):
        for i in range(pooled_rows):
            for j in range(pooled_cols):
                window = input_matrix[2 * i:2 * i + 2, 2 * j:2 * j + 2, c]
                max_idx = np.unravel_index(np.argmax(window), window.shape)
                output_matrix[i, j, c] = window[max_idx]
                pool_indices[i, j, c] = [2 * i + max_idx[0], 2 * j + max_idx[1]]
    return output_matrix, pool_indices
```

## 3 >> ReLU 和 Softmax 函数

ReLU 直接和 0 取 max 即可。

```
def relu(x):
    return np.maximum(0, x)
```

下面介绍 Softmax 函数，因为全连接层的维度的 [fc_input_size, 10]，所以进行点乘之后得到一个 (10,) 这个形状的列表，按照 Softmax 的一般计算方法就行，都减去最大值，然后取指数除以总和。

```
def softmax(x):
    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
    return e_x / e_x.sum(axis=-1, keepdims=True)
```

值得注意的是，上面的参数 axis=-1 非常的关键，要是等于 0 的话，只能适配单样本输入的情况，要是等于 1，的话能适应多样本的情况，但是单样本会报错没有 axis=1 这个轴，axis=-1，当是单样本的话就算 0 轴，当是多样本的话就算 1 轴。

## 4 >> 前向传播

先在 `image` 后面添加一个维度，使其符合正常的输入形式，[input_height, input_width, input_channels]，之后进行卷积1、激活1、池化1、卷积2、激活2、池化2，全连接，Softmax 得到最终的正确率。

```
def forward(image, conv_kernel1, conv_kernel2, fc_weights, fc_bias):
    image = np.expand_dims(image, axis=-1)
    convolved1 = convolve_2D(image, conv_kernel1)
    activated1 = relu(convolved1)
    pooled1, pool_indices1 = max_pooling(activated1)
    convolved2 = convolve_2D(pooled1, conv_kernel2)
    activated2 = relu(convolved2)
    pooled2, pool_indices2 = max_pooling(activated2)
    flattened = pooled2.flatten()
    fc_output = np.dot(flattened, fc_weights) + fc_bias
    predictions = softmax(fc_output)
    return convolved1, activated1, pooled1, pool_indices1, convolved2, activated2, pooled2, pool_indices2, flattened, fc_output, predictions
```

## 5 >> 构建步骤

- 004 >> [反向传播](https://github.com/fangqing408/00-MNIST/blob/master/recognition/004.md)
- 005 >> [模型训练](https://github.com/fangqing408/00-MNIST/blob/master/recognition/005.md)
- 006 >> [模型保存和预测](https://github.com/fangqing408/00-MNIST/blob/master/recognition/006.md)
